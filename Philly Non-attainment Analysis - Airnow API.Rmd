---
title: "Philly NAA Analysis"
author: "Microscone"
date: "7/22/2020"
output: html_document
---
## Purpose

This analysis is to review the forecasts made by STI in a given month.

Forecast and daily max 8-hour ozone data was retrieved from the EPA AQS API. 

```{r, include = FALSE}
library(httr)
library(jsonlite)
library(tidyverse)
library(lubridate)
library(gmodels)
library(knitr)
library(kableExtra)
library(leaflet)
library(geojsonio)
```

```{r}
#enter the number of days in the month you want to analyze here:
#Enter the date of the first of the month that you want to analyze, in YYYY-MM-DD Format. 
#For instance, if you want to analyze June of 2020, enter "2020-06-01"
# Month_to_analyze <- "2020-07-01"
```


```{r, include = FALSE}
#Enter the year of data you want to analyze
Year_to_analyze <- "2020"

#converts the year to a date at the start of the ozone season
ozone_start_date <- as.Date(paste0(Year_to_analyze,"-05-01"))

#gets the date of "today"
Date_Today <- Sys.Date()

#converts the date of "today" to a character value without dashes
Today_characters <- paste0(substr(Date_Today,6,7),substr(Date_Today,9,10))

#creates a list of dates between the start of the ozone season and "today"
#removes the dashes from the dates and converts them all to characters
day_list <- str_remove_all(as.character(seq(ozone_start_date,Date_Today,1)),"-")

#main url for airnow daily files
airnowtech_files <- "https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow/"

#name used for daily data files from airnow, which list the max concentrations for pollutants at each monitor each day
fileName <- "daily_data_v2.dat"

#----------
#ALTHOUGH NOT USED, THIS SECTION DOWNLOADS ALL DAT FILES TO A FOLDER, AS OPPOSED TO OPENING IN A DATA FRAME 
# #creates a default folder on the computer
# airnow_folder <- "c:/airnow/"
# 
# #creates a subfolder
# ifelse(!dir.exists(file.path(airnow_folder,Year_to_analyze)), dir.create(file.path(airnow_folder,Year_to_analyze)), FALSE)
# 
# #creates a variable for the path of the subfolder
# YOC_folder <- paste0(airnow_folder,Year_to_analyze,sep = "/")
# 
# #new subfolder name
# dat_folder_name <- "Daily_Data_Files"
# 
# #creates another subfolder
# ifelse(!dir.exists(file.path(YOC_folder,dat_folder_name)), dir.create(file.path(YOC_folder,dat_folder_name)), FALSE)
# 
# #another variable for the path of the final folder
# dat_folder <- paste0(YOC_folder,dat_folder_name,sep = "/")
# 
# #downloads the daily dat files for the selected year for the ozone season and places them in the download folder created.
# for (i in day_list){
#   temp_url <- paste0(airnowtech_files,Year_to_analyze,"/",i,"/",fileName)
#   destination_file <- paste0(dat_folder,i,fileName)
#   download.file(temp_url,destination_file)
# }
#---------

#empty data frame
df_total = data.frame()

#loop to read the dat files for the selected days and copy into the empty data frame
for (i in day_list){
  temp_url <- paste0(airnowtech_files,Year_to_analyze,"/",i,"/",fileName)
  data <- read.delim(temp_url, header = FALSE, sep="|", skip=2, as.is=TRUE)
  df_total <- rbind(df_total,data)
}

#list of names for the header of the data frame
headers <- c("Date","Monitor_ID","SiteName","Param_Name","Units","Value","Averaging_Period","Data_Source",
            "AQI_Value","AQI_Category","Latitude","Longitude","AQSID")

#renaming header of data frame
colnames(df_total) <- headers

#copying data frame to a new working data frame
AQ2020 <- df_total

#converting Date field from a character to a date.
AQ2020$Date <- as.Date(AQ2020$Date)

#philly NAA monitors: 
Philly_monitors <- as.character(c(100031007,
100031010,
100031013,
100032004,
240150003,
340010006,
340070002,
340071001,
340110007,
340150002,
340210005,
340219991,
340290006,
420170012,
420290100,
420450002,
420910013,
421010004,
421010024,
421010048))

#selecting only the records for monitors in the Philly NAA for 8hr ozone average max values
PhillyNAA_daily_max <- AQ2020 %>% 
  filter(Monitor_ID %in% Philly_monitors) %>%
  filter(Param_Name == "OZONE-8HR") %>%
  rename(c("Actual_AQI" = AQI_Value), c("Avg_8hr" = Value))


#selecting the 4 highest 8hr ozone max values for each monitor in the Philly NAA
PhillyNAA_4_highest <- AQ2020 %>% 
  filter(Monitor_ID %in% Philly_monitors) %>%
  filter(Param_Name == "OZONE-8HR") %>%
  rename(c("Actual_AQI" = AQI_Value), c("Avg_8hr" = Value)) %>%
  group_by(SiteName) %>% 
  arrange(desc(Actual_AQI)) %>% 
  slice(1:4) 
  
```



```{r, include = FALSE}
#creating a unique list of monitors in Philly NAA and their coordinates
NAA_Sites <- PhillyNAA_daily_max %>%
  group_by(SiteName) %>%
  slice(1) %>%
  select(SiteName,Latitude,Longitude)

# reading GeoJSON file for DE county boundaries as an "sp" object
Philly_NAA_Counties <- geojson_read("Philly_NAA_Counties_4326.geojson", what = "sp")

# The Leaflet map widget is set to a variable "map".
# Layers are defined for use with an interactive layer display.
map <- leaflet(NAA_Sites) %>% 
  
  #a third-party basemap is added
  addProviderTiles(providers$CartoDB.Positron) %>%

  # a polygon layer is added from the Philly NAA counties sp object and its outline color and opacity are set
  addPolygons(data=Philly_NAA_Counties,
              col = 'red',
              fillOpacity = 0) %>%
  
  # add circle markers for the monitors
  addCircleMarkers(~Longitude,
                   ~Latitude,
                   popup = ~as.character(SiteName),
                   label = ~as.character(SiteName),
                   radius = 5,
                   stroke = FALSE, fillOpacity = 0.75)

#the map object is called, to create the leaflet map.
map
```


```{r, include = FALSE}
#Now, to acquire the actual max ozone measured at any monitor in the state for each day.

# #create a vector of the last day of the month:
# Month_to_analyze_end <-  ceiling_date(ymd(Month_to_analyze), unit = "month")-days(1)

Date_Today <- Sys.Date()

#create the URL for the API using the date of interest
get_url <- paste0("http://www.airnowapi.org/aq/data/?startDate=2020-05-01T00&endDate=",Date_Today,"T23&parameters=OZONE&verbose=1&BBOX=-75.95,39.3,-74.3,40.38&dataType=B&format=application/json&nowcastonly=0&includerawconcentrations=1&API_KEY=",
#"428E6635-36C1-4DA8-A90A-ED982938204A") #SHANE API KEY
"0269BB74-0C96-4CA8-A479-9FDA840A7A5E") #MARK API KEY

#API Call
Monitorin_data_raw <- GET(url = get_url)

# converting API results to DF
Monitorin_data_PA <-  fromJSON(rawToChar(Monitorin_data_raw$content))
Monitorin_data_PA


#philly NAA monitors: 
Philly_monitors <- c(100031007,
100031010,
100031013,
100032004,
240150003,
340010006,
340070002,
340071001,
340110007,
340150002,
340210005,
340219991,
340290006,
420170012,
420290100,
420450002,
420910013,
421010004,
421010024,
421010048)

#selecting only the max daily AQI for the month
Monitoring_data_PA_daily_max <- Monitorin_data_PA %>% 
  filter(FullAQSCode %in% Philly_monitors) %>% 
  rename(c("Actual_AQI" = AQI), c("8-hr Average" = Value)) %>%
  mutate(Time_int = hour(ymd_hm(UTC))) %>% 
  mutate(Date = as.Date(UTC)) %>% 
  filter(!Time_int %in% c(5:11)) %>% 
  select(-Time_int) %>% 
  group_by(Date) %>% 
  arrange(desc(Actual_AQI)) %>% 
  slice(1) %>% 
  ungroup() 

Monitoring_data_PA_daily_max

Number_of_exceedances <- Monitoring_data_PA_daily_max %>% 
    filter(Actual_AQI > 100)
```
